{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Malware Analysis Using Hierarchical Attention Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem description\n",
    "Static malware detection aims to identify a malicious executable/binary file *without running it* on a host system. In this notebook we demonstrate malware detection using a subset of the [Microsoft Malware Classification Challenge (BIG 2015)](https://www.kaggle.com/c/malware-classification), to identify two classes of malware (class 1 and 2 for example: Ramnit and Lollipop). The datasets consist of disassembly dumps of binary files, generated using the IDA disassembler tool.\n",
    "\n",
    "This is a sample from the .text section in a disassembled executable file:\n",
    "\n",
    "![Disassembled code sample](sampleIDAKaggle.png)\n",
    "\n",
    "### Proposed solution\n",
    "The solution demonstrated in this notebook is inspired by the domain of natural language processing, and document classification in particular. Determining the sentiment and/or topic expressed in a text document requires a deeper understanding of the words, sentences, language structure, writing style, and syntactic and semantic structure of the document.\n",
    "\n",
    "Yang, Zichao et al proposed a [hierachical attention network for document classification](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/Hierarchical-Attention-Networks-for-Document-Classification.pdf)), presented at [NAACL 2016](http://aclweb.org/anthology/N/N16/). The solution leverages the hierarchical structure of a document, from words to sentences to documents, mirrored in a multi-layer [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network) with special *attention* layers applied at the word and the sentence levels. The architecture of the Hierarchical Attention Network (HAN) is shown in the figure below. The overall process is nicely  described in details in this [blog](https://explosion.ai/blog/deep-learning-formula-nlp).\n",
    "\n",
    "![Hierarchical Attention Network](HierachicalAttention.png)\n",
    "\n",
    "We propose a static malware detection solution that leverages multi-layers of *memory and understanding* of the sequence of operations in the disassembly information based on hiearchical attention networks. If we think of the sequence of assembly code operations as analogous to sequence of words in text, and groups of operations as sentences, classifying patterns of assembly code could then be viewed as classifying documents.\n",
    "\n",
    "![HAN for process analysis](HAN-proc-analysis1.png)\n",
    "\n",
    "### Some implementation details\n",
    "1. Data format: Disassembly dumps are represented as tab-separated tuples of (operation, operand #1, operand #2, ..). \n",
    "2. Pre-processing: Fields other than assembly operations are normalized to limit their variations. For e.g., memory addresses, files/folders are represented in a shortened form to collapse many values to a representative normalized form.\n",
    "3. Any number of fields can be included in model training, as defined in the parameter MAX_FIELDS.\n",
    "4. Each field in a process action tuple is equivalent to a *word*.\n",
    "5. Number of words per *sentence* and number of sentences in a *document* are configurable.\n",
    "6. Word embeddings can be initialized using pre-trained vectors, or left uninitialized. Defined by parameter USE_WORD2VEC.\n",
    "7. Other configurable options define various network dimensions, learning hyper-parameters, data sampling options, etc.\n",
    "8. Deep learning framework: Keras with a CNTK backend, with GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HAN code in this notebook is based on the LSTM HAN implementation found in this [GitHub notebook](https://github.com/anargyri/lstm_han/blob/master/hatt_archive_cntk.ipynb) by Andreas Argyriou. The base notebook is based on [Richard Liao's implementation of hierarchical attention networks](https://github.com/richliao/textClassifier/blob/master/textClassifierHATT.py) and a related [Google group discussion](https://groups.google.com/forum/#!topic/keras-users/IWK9opMFavQ). The notebook also includes code from [Keras documentation](https://keras.io/) and [blog](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) as well as this [word2vec tutorial](http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'cntk'\n",
    "from cntk.device import try_set_default_device, gpu, cpu\n",
    "from cntk.cntk_py import set_fixed_random_seed\n",
    "from cntk.cntk_py import set_computation_network_trace_level, set_checked_mode\n",
    "from cntk.cntk_py import force_deterministic_algorithms, disable_forward_values_sharing\n",
    "from cntk.debugging import debug_model\n",
    "\n",
    "# Set default device - negative for cpu (optional)\n",
    "gpu_device = 1\n",
    "if gpu_device >= 0:\n",
    "    try_set_default_device(gpu(gpu_device))\n",
    "else:\n",
    "    try_set_default_device(cpu())\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, regularizers, optimizers\n",
    "from keras.callbacks import History, CSVLogger, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read clean and ransomware Action -> Target tuples from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 23813917 class1 tuples\n",
      "Read 17441432 class2 tuples\n"
     ]
    }
   ],
   "source": [
    "class1_srcfile = './data/Malware_class1_ng2a.txt'\n",
    "class2_srcfile = './data/Malware_class2_ng2a.txt'\n",
    "\n",
    "class1_srctext = open(class1_srcfile).readlines()\n",
    "class2_srctext = open(class2_srcfile).readlines()\n",
    "\n",
    "print('Read %d class1 tuples' % len(class1_srctext))\n",
    "print('Read %d class2 tuples' % len(class2_srctext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text egment para public UPP use\\n', 'assume cs text\\n', 'assume es othing ss othing ds data fs othing gs othing\\n', 'sub proc near\\n', 'var dword ptr op Ch\\n']\n"
     ]
    }
   ],
   "source": [
    "print(class1_srctext[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['include uni inc\\n', 'p\\n', 'mmx\\n', 'model flat\\n', 'text egment para public UPP use\\n']\n"
     ]
    }
   ],
   "source": [
    "print(class2_srctext[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configurable parameters\n",
    "\n",
    "1. Set the dimensions of the input and the embedding. Because of the hierarchical nature of the network, the input has to be a 3-dimensional tensor of fixed size (sample_size x n_sentences x n_words). \n",
    "   <br>MAX_SENT_LEN : the number of words in each sentence (a word in any token appearing in a process action tuple). \n",
    "   <br>MAX_SENTS : the number of sentences in each document.\n",
    "   <br>MAX_NB_WORDS : the size of the word encoding (number of most frequent words to keep in the vocabulary)\n",
    "   <br>**Note:** MAX_NB_WORDS is automatically adjusted to match the action tuples vocabulary size\n",
    "   <br>EMBEDDING_DIM : the dimensionality of the word embedding\n",
    "   <br>GRU_UNITS: the dimensionality of the GRU layers\n",
    "   <br>CONTEXT_DIM: the dimensionality of attention layers\n",
    "<br><br>   \n",
    "2. Set the runtime parameters:\n",
    "   <br>MAX_FIELDS: number of fields to include form each process action tuple\n",
    "   <br>BY_PROCESS: if True, indicates stratified sampling by process/executable, i.e., actions in one process are either training or test\n",
    "   <br>if false, sampling is done at a seqnece (sentence) level\n",
    "   <br>use_ratio, balance_ratio, over_sample: control how sampling is done to oprionally balance class distribution\n",
    "<br><br> \n",
    "3. Set the learning hyper-parameters:\n",
    "   <br>LEARN_RATE: learning rate\n",
    "   <br>REG_PARAM:  regularization parameter\n",
    "   <br>BATCH_SIZE: number of sequences to include per training batch\n",
    "   <br>NUM_EPOCHS: number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequence/sentence dimensions\n",
    "MAX_FIELDS      = 2                      # which tuple fields to include from dataset\n",
    "MAX_SENT_LENGTH = 20 * MAX_FIELDS        # multiple of MAX_FIELDS tuples\n",
    "MAX_SENTS       = 5\n",
    "MAX_NB_WORDS    = 100000    # maximum vocabulary size to include, if too high actual vocab size will be used\n",
    "MIN_FREQ        = 10        # (optional) limit vocabulary size by token frequency\n",
    "SENT_SEPARATOR  = '<eos>'\n",
    "BY_PROCESS      = True      # sample and split by process or by sequence\n",
    "use_ratio       = 1.0       # limit training size if needed\n",
    "balance_ratio   = -1        # ratio to balance classes in multiples of the under-represented class, use -1 for no balancing\n",
    "over_sample     = False     # balance by over sampling the minority class, otherwise under sample the majority class\n",
    "\n",
    "# Model definition parameters\n",
    "USE_WORD2VEC  = False       # initialize embeddings with pre-trained word2vec weights\n",
    "ORDER_DOCS    = False       # order sequences by length prior to training - not needed since lengths are mostly equal\n",
    "EMBEDDING_DIM = 50\n",
    "GRU_UNITS     = 100\n",
    "CONTEXT_DIM   = 100\n",
    "\n",
    "# Learning hyper-parameters\n",
    "REG_PARAM     = 1e-13\n",
    "LEARN_RATE    = 0.01\n",
    "BATCH_SIZE    = 32\n",
    "NUM_EPOCHS    = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process input action tuples to construct sentences, sequences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sequences(source_text, label, proc_start=0):\n",
    "    global sentences, labels, texts, processes\n",
    "    token_count = 0\n",
    "    sent_count  = 0\n",
    "    seq_count   = 0\n",
    "    total_count = 0\n",
    "    total_sent  = 0\n",
    "    total_seq   = 0\n",
    "    total_proc  = 0\n",
    "    text  = ''\n",
    "    sents = []\n",
    "    \n",
    "    for line in source_text:\n",
    "        line   = line.strip().lower()\n",
    "        line = re.sub('\\s+', ' ', line).strip()\n",
    "        tokens = line.split()[0:MAX_FIELDS]\n",
    "        text  += ' '.join(tokens) + ' '\n",
    "        #tokens = line.split()\n",
    "        #text  += line + ' '\n",
    "        token_count += len(tokens)\n",
    "        total_count += len(tokens)\n",
    "    \n",
    "        if token_count >= MAX_SENT_LENGTH or tokens[0] == SENT_SEPARATOR:\n",
    "            sents.append(text.strip())\n",
    "            sent_count += 1\n",
    "            total_sent += 1\n",
    "            token_count = 0\n",
    "            text = ''\n",
    "        \n",
    "        if sent_count == MAX_SENTS or tokens[0] == SENT_SEPARATOR:\n",
    "            texts.append(' '.join(sents))\n",
    "            sentences.append(sents)\n",
    "            seq_count += 1\n",
    "            total_seq += 1\n",
    "            sents      = []\n",
    "            sent_count = 0\n",
    "            if tokens[0] == SENT_SEPARATOR:\n",
    "                proc_end   = proc_start + seq_count\n",
    "                processes.append([proc_start, proc_end, seq_count, label])\n",
    "                proc_start = proc_end\n",
    "                seq_count = 0\n",
    "                total_proc += 1\n",
    "\n",
    "    labels = np.concatenate((labels, np.repeat(label, total_seq)), axis=0)\n",
    "    print('Processed sequences for label = %d' % label)\n",
    "    print('Processes = %d' % total_proc)\n",
    "    print('Sequences = %d' % total_seq)\n",
    "    print('Sentences = %d' % total_sent)\n",
    "    print('Tokens    = %d' % total_count)\n",
    "    \n",
    "    return proc_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform input data into sequences and sentences, with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sequences for label = 0\n",
      "Processes = 424\n",
      "Sequences = 219243\n",
      "Sentences = 1095348\n",
      "Tokens    = 44270882\n",
      "Processed sequences for label = 1\n",
      "Processes = 691\n",
      "Sequences = 151029\n",
      "Sentences = 753759\n",
      "Tokens    = 30444980\n",
      "Total # of processes       = 1115\n",
      "Total # of text sequences  = 370272\n",
      "Total # of sentence groups = 370272\n",
      "Total # of labels          = 370272\n"
     ]
    }
   ],
   "source": [
    "# Extract sequences and sentences from clean and ransom source text\n",
    "sentences = []\n",
    "labels    = np.empty(0)\n",
    "texts     = []\n",
    "processes = []\n",
    "\n",
    "next_proc_start = 0\n",
    "next_proc_start = get_sequences(class1_srctext, 0, proc_start = next_proc_start)\n",
    "next_proc_start = get_sequences(class2_srctext, 1, proc_start = next_proc_start)\n",
    "\n",
    "print('Total # of processes       = %d' % len(processes))\n",
    "print('Total # of text sequences  = %d' % len(texts))\n",
    "print('Total # of sentence groups = %d' % len(sentences))\n",
    "print('Total # of labels          = %d' % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 6, 6, 0], [6, 372, 366, 0], [372, 446, 74, 0], [446, 1881, 1435, 0], [1881, 1975, 94, 0], [1975, 2183, 208, 0], [2183, 2263, 80, 0], [2263, 2577, 314, 0], [2577, 2804, 227, 0], [2804, 3864, 1060, 0]]\n",
      "[[368876, 368972, 96, 1], [368972, 369270, 298, 1], [369270, 369568, 298, 1], [369568, 369887, 319, 1], [369887, 369914, 27, 1], [369914, 370083, 169, 1], [370083, 370116, 33, 1], [370116, 370155, 39, 1], [370155, 370240, 85, 1], [370240, 370272, 32, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(processes[0:10])\n",
    "print(processes[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text egment assume cs assume es sub proc var dword var byte var dword var dword arg dword arg dword arg dword push fff push upp mov regex push regex mov large sub esp mov regex push esi push regex lea regex mov esp call ds mov regex push regex mov regex mov esp call ds mov esi push regex mov regex call ds lea regex mov esp mov byte call ds mov regex mov regex pop esi mov large esp ch retn sub endp align public subs16 subs16 proc object dword module dword msg tagmsg var dword var dword var byte var byte var byte var dword var byte addr dword var byte var byte var dword var dword var dword dest word var byte var byte var byte var dword var dword value dword subs8 dword arg dword push ebp mov ebp and esp sub esp mov regex test regex mov regex push regex push esi mov esp push edi jz loc mov regex jz loc mov regex mov esi lea edi rep movsd movsw xor regex mov regex lea edi rep stosd stosw push lea regex push regex push regex call ds esp ch push regex lea regex\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "#print(texts[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the process action vocabulary using a Keras tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 25573 unique tokens.\n",
      "Vocabulary size with frequency > 10 = 2844\n",
      "Max number of words = 2845\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "# limit vocabulary size by token frequence\n",
    "vocab = [k for k in tokenizer.word_counts.keys() if tokenizer.word_counts[k] > MIN_FREQ]\n",
    "print('Vocabulary size with frequency > %d = %d' % (MIN_FREQ, len(vocab)))\n",
    "\n",
    "if len(vocab) < MAX_NB_WORDS:\n",
    "    MAX_NB_WORDS = len(vocab) + 1      # index 0 is not used\n",
    "\n",
    "print('Max number of words = %d' % MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.word_counts)\n",
    "#print(tokenizer.texts_to_matrix(sentences[0][0], mode='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the data into the 3D format required for the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((len(sentences), MAX_SENTS, MAX_SENT_LENGTH), dtype='float32')\n",
    "doc_lst = []\n",
    "\n",
    "# keep the MAX_NB_WORDS most frequent words and replace the rest with 'UNK'\n",
    "# truncate to the first MAX_SENTS sentences per doc and MAX_SENT_LENGTH words per sentence\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, sent in enumerate(sentence):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data[i, j, k] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    k = k + 1\n",
    "            doc_lst.append(words_in_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370272, 5, 40) 1849107\n",
      "(370272,)\n",
      "5\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, len(doc_lst))\n",
    "print(labels.shape)\n",
    "print(len(sentences[0]))\n",
    "print(len(texts[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the class labels to one-hot categorical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (370272, 5, 40)\n",
      "Shape of label tensor: (370272, 2)\n"
     ]
    }
   ],
   "source": [
    "y_all = to_categorical(np.asarray(labels)).astype('int32')\n",
    "x_all = data\n",
    "\n",
    "print('Shape of data tensor:', x_all.shape)\n",
    "print('Shape of label tensor:', y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes = y_all.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract word embedding vectors from a pre-trained word2vec model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train word2vec on the sentences to initialize the word embedding \n",
    "def get_embedding_matrix(sents, word_index, embedding_dim=100, max_num_words=1000):\n",
    "    import gensim, logging\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    # use skip-gram\n",
    "    word2vec_model = gensim.models.Word2Vec(sents, min_count=1, size=embedding_dim, sg=1, workers=os.cpu_count())\n",
    "    \n",
    "    # Create the initial embedding matrix from the output of word2vec\n",
    "    embeddings_index = {}\n",
    "\n",
    "    for word in word2vec_model.wv.vocab:\n",
    "        coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "    # Empty embeddings for padding UNK terms\n",
    "    embeddings_index['UNK'] = np.zeros(embedding_dim, dtype='float32')\n",
    "    \n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    # Initial embedding\n",
    "    embedding_matrix = np.zeros((max_num_words + 1, embedding_dim))\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None and i < max_num_words:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        elif i == max_num_words:\n",
    "            # index MAX_NB_WORDS in data corresponds to 'UNK'\n",
    "            embedding_matrix[i] = embeddings_index['UNK']\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Function to define the word embeddings layer, with or without word2vec weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define embedding layer structure and optionally initialize weights\n",
    "def get_embedding_layer(embedding_dim=100, embedding_matrix=None, max_num_words=1000, max_sent_length=40, reg_param=1e-13):\n",
    "    l2_reg = regularizers.l2(reg_param)\n",
    "\n",
    "    if embedding_matrix is not None:\n",
    "        # Embedding layer initialized with word2vec coefficients\n",
    "        embedding_layer = Embedding(max_num_words + 1,\n",
    "                            embedding_dim,\n",
    "                            input_length=max_sent_length,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True,\n",
    "                            embeddings_regularizer=l2_reg,\n",
    "                            weights=[embedding_matrix])\n",
    "    else:\n",
    "        # Embedding layer with no pre-trained weiths\n",
    "        embedding_layer = Embedding(max_num_words + 1,\n",
    "                            embedding_dim,\n",
    "                            input_length=max_sent_length,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True,\n",
    "                            embeddings_regularizer=l2_reg)\n",
    "\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of a custom layer implementing the attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "    def __init__(self, regularizer=None, context_dim=100, **kwargs):\n",
    "        self.regularizer = regularizer\n",
    "        self.context_dim = context_dim\n",
    "        self.supports_masking = True\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3        \n",
    "        self.W = self.add_weight(name='W', shape=(input_shape[-1], self.context_dim), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.b = self.add_weight(name='b', shape=(self.context_dim,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.u = self.add_weight(name='u', shape=(self.context_dim,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)        \n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.dot(K.tanh(K.dot(x, self.W) + self.b), K.expand_dims(self.u))\n",
    "        ai = K.exp(eij)\n",
    "        alphas = ai / K.sum(ai, axis=1)\n",
    "        if mask is not None:\n",
    "            # use only the inputs specified by the mask\n",
    "            alphas *= K.expand_dims(mask)\n",
    "        weighted_input = K.dot(K.transpose(x), alphas)\n",
    "        return K.reshape(weighted_input, (weighted_input.shape[0],))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(AttLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create the network model structure\n",
    "GRU_UNITS is the dimensionality of each GRU output (the number of GRU units). GRU_IMPL = 2 selects a matricized RNN implementation which is more appropriate for training on a GPU. \n",
    "\n",
    "There are two levels of models in the definition. The sentence model `sentEncoder` is shared across all sentences in the input document.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(n_classes, reg_param=1e-13, embedding_dim=100, embedding_matrix=None, gru_units=100, context_dim=100, max_sents=5, max_sent_length=40, max_num_words=1000):\n",
    "    GPU_IMPL = 2 \n",
    "    l2_reg = regularizers.l2(reg_param)\n",
    "\n",
    "    sentence_input = Input(shape=(max_sent_length,), dtype='float32')\n",
    "    embedding_layer = get_embedding_layer(embedding_dim=embedding_dim, embedding_matrix=embedding_matrix,\n",
    "                                          max_num_words=max_num_words, max_sent_length=max_sent_length, \n",
    "                                          reg_param=reg_param)\n",
    "    embedded_sequences = embedding_layer(sentence_input)\n",
    "    l_lstm = Bidirectional(GRU(gru_units, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                           implementation=GPU_IMPL))(embedded_sequences)\n",
    "    l_att = AttLayer(regularizer=l2_reg, context_dim=context_dim)(l_lstm)            \n",
    "    sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "    doc_input = Input(shape=(max_sents, max_sent_length), dtype='float32')\n",
    "    doc_encoder = TimeDistributed(sentEncoder)(doc_input)\n",
    "    l_lstm_sent = Bidirectional(GRU(gru_units, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                                implementation=GPU_IMPL))(doc_encoder)\n",
    "    l_att_sent = AttLayer(regularizer=l2_reg, context_dim=context_dim)(l_lstm_sent) \n",
    "    preds = Dense(n_classes, activation='softmax', kernel_regularizer=l2_reg)(l_att_sent)\n",
    "    model = Model(doc_input, preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to train the HAN model (uses 10% of train data for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_x, train_y, model, model_path, batch_size=32, num_epochs=10, reg_param=1e-13, show_hist=True):\n",
    "    set_fixed_random_seed(1)                           # fix a random seed for CNTK components\n",
    "    #set_computation_network_trace_level(1000)         # debugging mode\n",
    "    disable_forward_values_sharing()                   # to debug Titan X NaN loss issue\n",
    "\n",
    "    fname = './kaggle_malware_classification_f%d' % (MAX_FIELDS)\n",
    "\n",
    "    if USE_WORD2VEC:\n",
    "        filepath = '%s/checkpoint-{epoch:02d}-f%d-dim=%d-w2v-strat-lr=%.2f.hdf5' % (model_path, MAX_FIELDS, EMBEDDING_DIM, LEARN_RATE)\n",
    "    else:\n",
    "        filepath = '%s/checkpoint-{epoch:02d}-f%d-dim=%d-now2v-strat-lr=%.2f.hdf5' % (model_path, MAX_FIELDS, EMBEDDING_DIM, LEARN_RATE)\n",
    "\n",
    "    sgd_optimizer     = optimizers.SGD(lr=LEARN_RATE, nesterov=True)\n",
    "    #sgd_optimizer     = optimizers.SGD(lr=LEARN_RATE, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adam_optimizer    = optimizers.Adam(lr=LEARN_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    adagrad_optimizer = optimizers.Adagrad(lr=LEARN_RATE, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd_optimizer,\n",
    "              metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    train_x = train_x.astype(np.float32)\n",
    "    #train_y = train_y.astype(np.float32)\n",
    "    \n",
    "    # set callback functions\n",
    "    history = History()\n",
    "    csv_logger = CSVLogger('./{0}_{1}.log'.format(fname, reg_param), separator=',', append=True)\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=False)\n",
    " \n",
    "    print(str(datetime.now()))\n",
    "    t1 = time.time()\n",
    "    # for final training, train without validation split\n",
    "    # hist_results = model.fit(train_x[ind,:,:], train_y[ind,:], epochs=num_epochs, batch_size=batch_size, shuffle=False, \n",
    "    #          callbacks=[checkpoint, history, csv_logger], verbose=2)\n",
    "    hist_results = model.fit(train_x, train_y, epochs=num_epochs, batch_size=batch_size, validation_split=0.1, shuffle=False, \n",
    "          callbacks=[checkpoint, history, csv_logger], verbose=2)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(str(datetime.now()))\n",
    "    print('Training time = %.3f' % (t2 - t1))\n",
    "    \n",
    "    if show_hist:\n",
    "        show_history(hist_results)\n",
    "    \n",
    "    return model, hist_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to evaluate a trained HAN model using a test set and save prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_x, test_y, model, save=False, outfile=None):\n",
    "    test_x = test_x.astype(np.float32)\n",
    "    #test_y = test_y.astype(np.float32)\n",
    "\n",
    "    print(str(datetime.now()))\n",
    "    t1    = time.time()\n",
    "    preds = model.predict(test_x)\n",
    "    t2    = time.time()\n",
    "    print(str(datetime.now()))\n",
    "    tdiff = t2 - t1\n",
    "    print('Evaluation time for %d sequences = %.3f secs --> %.6f sec/sequence\\n' % \n",
    "                                (len(preds), tdiff, tdiff/len(preds)))\n",
    "\n",
    "    #print(preds.shape, test_y.shape)\n",
    "    y_true = np.zeros(test_y.shape[0])\n",
    "    y_true[y_test[:,1] == 1] = 1\n",
    "    y_pred = preds.argmax(axis=1)\n",
    "    print(\"Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(y_true, y_pred),\n",
    "                                           roc_auc_score(y_true, y_pred)))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    plot(fpr, tpr)\n",
    "    xlabel('FPR')\n",
    "    ylabel('TPR')\n",
    "\n",
    "    # Save prediction results for offline analysis\n",
    "    if save and outfile is not None:\n",
    "        ff = open(ofname, 'w')\n",
    "        pid = 0\n",
    "        sid = 0\n",
    "        if BY_PROCESS:\n",
    "            ff.write('test_pid\\tproc_sid\\tseq_state\\ty_true\\ty_pred\\tprob[0]\\tprob[1]\\tmatch?\\n')\n",
    "            for i in range(len(y_true)):\n",
    "                match = (y_true[i] == y_pred[i])\n",
    "                if text_test[i].endswith('<eos>'):\n",
    "                    seq = '<eos>'\n",
    "                else:\n",
    "                    seq = '<inp>'\n",
    "                ff.write('%d\\t%d\\t%s\\t%d\\t%d\\t%10.8f\\t%10.8f\\t%d\\n' % (pid, sid, seq, y_true[i], y_pred[i], preds[i, 0], preds[i, 1], match))\n",
    "                if text_test[i].endswith('<eos>'):\n",
    "                    pid += 1\n",
    "                    sid = 0\n",
    "                else:\n",
    "                    sid += 1\n",
    "        else:\n",
    "            ff.write('test_sid\\tseq_state\\ty_true\\ty_pred\\tprob[0]\\tprob[1]\\tmatch?\\n')\n",
    "            for i in range(len(y_true)):\n",
    "                match = (y_true[i] == y_pred[i])\n",
    "                if text_test[i].endswith('<eos>'):\n",
    "                    seq = '<eos>'\n",
    "                else:\n",
    "                    seq = '<inp>'\n",
    "                ff.write('%d\\t%s\\t%d\\t%d\\t%10.8f\\t%10.8f\\t%d\\n' % (sid, seq, y_true[i], y_pred[i], preds[i, 0], preds[i, 1], match))\n",
    "                sid += 1 \n",
    "        ff.close()\n",
    "        print('Results saved in %s' % outfile)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to report training and validation progress during model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin model training process\n",
    "If USE_WORD2VEC is Ture, train word2vec on all documents in order to initialize the word embedding. Do not ignore rare words (min_count=1). Use skip-gram as the training algorithm (sg=1).<br><br>\n",
    "**Note:** Using a pre-trained word2vec model is not required if training data is large enough. Experiments with and without pre-training word2vec model produces similar results using this training data and a few training epochs. The word embeddings are learned in the first 1-2 training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if USE_WORD2VEC:\n",
    "    embedding_matrix = get_embedding_matrix(doc_lst, word_index, embedding_dim=EMBEDDING_DIM, max_num_words=MAX_NB_WORDS)\n",
    "else:\n",
    "    embedding_matrix = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare train/test data split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a balanced subsample (optional) and split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "if BY_PROCESS:\n",
    "    num_samples = len(processes)\n",
    "    train_size  = np.int(num_samples * use_ratio * 0.8)\n",
    "    test_size   = np.int(num_samples * use_ratio) - train_size\n",
    "    random_idx  = np.random.permutation(num_samples)\n",
    "    ptrain_idx, ptest_idx = random_idx[:train_size], random_idx[-test_size:]\n",
    "    p_train, p_test = [processes[i] for i in ptrain_idx], [processes[i] for i in ptest_idx]\n",
    "\n",
    "    train_idx, test_idx = [], []\n",
    "    for i, proc in enumerate(p_train):\n",
    "        train_idx.extend(range(proc[0], proc[1]))\n",
    "        np.random.shuffle(train_idx)\n",
    "    for i, proc in enumerate(p_test):\n",
    "        test_idx.extend(range(proc[0], proc[1]))\n",
    "        #np.random.shuffle(test_idx)\n",
    "else:\n",
    "    num_samples = data.shape[0]\n",
    "    train_size  = np.int(num_samples * use_ratio * 0.8)\n",
    "    test_size   = np.int(num_samples * use_ratio) - train_size\n",
    "    random_idx  = np.random.permutation(num_samples)\n",
    "    train_idx, test_idx = random_idx[:train_size], random_idx[-test_size:]\n",
    "\n",
    "# Balance label distribution if balance_ratio > 0.0\n",
    "if balance_ratio > 0.0:\n",
    "    class_distrib = np.unique(y_all[train_idx,1], return_counts=True)\n",
    "    print('Original training class distribution = ', class_distrib)\n",
    "    min_rep_class = class_distrib[0][np.argsort(class_distrib[1])[0]]\n",
    "    max_rep_class = class_distrib[0][np.argsort(class_distrib[1])[-1]]\n",
    "    train_idx     = np.asarray(train_idx)\n",
    "    idx_min_class = train_idx[y_all[train_idx,1] == min_rep_class]\n",
    "    idx_max_class = train_idx[y_all[train_idx,1] == max_rep_class]\n",
    "    if over_sample:\n",
    "        #min_rep_incl  = int(class_distrib[1][max_rep_class] / balance_ratio)\n",
    "        new_idx_min_class = np.zeros(0, dtype= np.int)\n",
    "        for i in range(int(balance_ratio)):\n",
    "            new_idx_min_class = np.concatenate((new_idx_min_class, idx_min_class), axis=0)      # repeat min_class samples to min_rep_incl\n",
    "        idx_min_class = new_idx_min_class\n",
    "    else:\n",
    "        max_rep_incl  = int(class_distrib[1][min_rep_class] * balance_ratio)\n",
    "        idx_max_class = idx_max_class[:max_rep_incl]                                # limit max_class samples to max_rep_incl\n",
    "\n",
    "    train_idx     = np.concatenate((idx_min_class, idx_max_class), axis=0)      # merge positive and negative samples\n",
    "    np.random.shuffle(train_idx)                                                # reshuffle train indices\n",
    "    print('Final training class distribution    = ', np.unique(y_all[train_idx,1], return_counts=True))\n",
    "    \n",
    "x_train, x_test = x_all[train_idx,:], x_all[test_idx,:]\n",
    "y_train, y_test = y_all[train_idx,:], y_all[test_idx,:]\n",
    "#sent_train, sent_test = [sentences[i] for i in train_idx], [sentences[i] for i in test_idx]\n",
    "text_train, text_test = [texts[i] for i in train_idx], [texts[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115 892 223\n",
      "(array([0, 1]), array([181748, 120290], dtype=int64))\n",
      "(array([0, 1]), array([37495, 30739], dtype=int64))\n",
      "302038 68234\n"
     ]
    }
   ],
   "source": [
    "print(num_samples, train_size, test_size)\n",
    "print(np.unique(y_train[:,1], return_counts=True))\n",
    "print(np.unique(y_test[:,1],  return_counts=True))\n",
    "#print(len(sent_train), len(sent_test))\n",
    "print(len(text_train), len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ordering documents is not necessary for process analysis since number of sentences if fixed.<br>\n",
    "If ORDER_DOCS is True, order training data by the number of sentences in document (as suggested in the [Yang et al.] paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ORDER_DOCS:\n",
    "    doc_lengths = [len(r.split()) for r in text_train]\n",
    "    ind = np.argsort(doc_lengths)\n",
    "    #print(ind)\n",
    "    #print(doc_lengths[ind[0:10]])\n",
    "    #print(text_train[ind[0:10]])\n",
    "    x_train = x_train[ind,:,:]\n",
    "    y_train = y_train[ind,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train Hierarchical Attention Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 5, 40)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 200)            253100    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5, 200)            180600    \n",
      "_________________________________________________________________\n",
      "att_layer_2 (AttLayer)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 454,302\n",
      "Trainable params: 454,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2018-01-29 16:25:35.203654\n",
      "Train on 271834 samples, validate on 30204 samples\n",
      "Epoch 1/20\n",
      "Epoch 00000: saving model to ./checkpoints/checkpoint-00-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "888s - loss: 0.2941 - acc: 0.8793 - val_loss: 0.2083 - val_acc: 0.9249\n",
      "Epoch 2/20\n",
      "Epoch 00001: saving model to ./checkpoints/checkpoint-01-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "867s - loss: 0.1845 - acc: 0.9359 - val_loss: 0.1633 - val_acc: 0.9442\n",
      "Epoch 3/20\n",
      "Epoch 00002: saving model to ./checkpoints/checkpoint-02-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "888s - loss: 0.1509 - acc: 0.9483 - val_loss: 0.1397 - val_acc: 0.9533\n",
      "Epoch 4/20\n",
      "Epoch 00003: saving model to ./checkpoints/checkpoint-03-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "905s - loss: 0.1289 - acc: 0.9570 - val_loss: 0.1200 - val_acc: 0.9612\n",
      "Epoch 5/20\n",
      "Epoch 00004: saving model to ./checkpoints/checkpoint-04-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "903s - loss: 0.1129 - acc: 0.9629 - val_loss: 0.1071 - val_acc: 0.9654\n",
      "Epoch 6/20\n",
      "Epoch 00005: saving model to ./checkpoints/checkpoint-05-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "879s - loss: 0.1015 - acc: 0.9669 - val_loss: 0.0981 - val_acc: 0.9689\n",
      "Epoch 7/20\n",
      "Epoch 00006: saving model to ./checkpoints/checkpoint-06-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "880s - loss: 0.0927 - acc: 0.9700 - val_loss: 0.0914 - val_acc: 0.9705\n",
      "Epoch 8/20\n",
      "Epoch 00007: saving model to ./checkpoints/checkpoint-07-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "891s - loss: 0.0850 - acc: 0.9726 - val_loss: 0.0866 - val_acc: 0.9724\n",
      "Epoch 9/20\n",
      "Epoch 00008: saving model to ./checkpoints/checkpoint-08-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "899s - loss: 0.0789 - acc: 0.9746 - val_loss: 0.0788 - val_acc: 0.9754\n",
      "Epoch 10/20\n",
      "Epoch 00009: saving model to ./checkpoints/checkpoint-09-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "889s - loss: 0.0736 - acc: 0.9764 - val_loss: 0.0736 - val_acc: 0.9774\n",
      "Epoch 11/20\n",
      "Epoch 00010: saving model to ./checkpoints/checkpoint-10-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "896s - loss: 0.0689 - acc: 0.9780 - val_loss: 0.0704 - val_acc: 0.9783\n",
      "Epoch 12/20\n",
      "Epoch 00011: saving model to ./checkpoints/checkpoint-11-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "893s - loss: 0.0649 - acc: 0.9793 - val_loss: 0.0672 - val_acc: 0.9794\n",
      "Epoch 13/20\n",
      "Epoch 00012: saving model to ./checkpoints/checkpoint-12-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "895s - loss: 0.0615 - acc: 0.9805 - val_loss: 0.0661 - val_acc: 0.9787\n",
      "Epoch 14/20\n",
      "Epoch 00013: saving model to ./checkpoints/checkpoint-13-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "885s - loss: 0.0584 - acc: 0.9818 - val_loss: 0.0729 - val_acc: 0.9765\n",
      "Epoch 15/20\n",
      "Epoch 00014: saving model to ./checkpoints/checkpoint-14-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "890s - loss: 0.0559 - acc: 0.9829 - val_loss: 0.0624 - val_acc: 0.9809\n",
      "Epoch 16/20\n",
      "Epoch 00015: saving model to ./checkpoints/checkpoint-15-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "895s - loss: 0.0535 - acc: 0.9833 - val_loss: 0.0614 - val_acc: 0.9802\n",
      "Epoch 17/20\n",
      "Epoch 00016: saving model to ./checkpoints/checkpoint-16-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "890s - loss: 0.0509 - acc: 0.9844 - val_loss: 0.0587 - val_acc: 0.9823\n",
      "Epoch 18/20\n",
      "Epoch 00017: saving model to ./checkpoints/checkpoint-17-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "871s - loss: 0.0495 - acc: 0.9847 - val_loss: 0.0615 - val_acc: 0.9799\n",
      "Epoch 19/20\n",
      "Epoch 00018: saving model to ./checkpoints/checkpoint-18-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "888s - loss: 0.0477 - acc: 0.9852 - val_loss: 0.0566 - val_acc: 0.9828\n",
      "Epoch 20/20\n",
      "Epoch 00019: saving model to ./checkpoints/checkpoint-19-f2-dim=50-now2v-strat-lr=0.01.hdf5\n",
      "879s - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0571 - val_acc: 0.9824\n",
      "2018-01-29 21:21:57.353396\n",
      "Training time = 17782.150\n",
      "dict_keys(['val_acc', 'val_loss', 'acc', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmKBYYwxJiQWGMYYY0JigWGMMSYk/x/V18zObHAqQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb7238f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb8486fda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "model = create_model(n_classes, reg_param=REG_PARAM,\n",
    "                     embedding_dim=EMBEDDING_DIM, embedding_matrix=embedding_matrix,\n",
    "                     gru_units=GRU_UNITS, context_dim=CONTEXT_DIM, \n",
    "                     max_sents=MAX_SENTS, max_sent_length=MAX_SENT_LENGTH, max_num_words=MAX_NB_WORDS)\n",
    "\n",
    "filepath = './checkpoints'\n",
    "model, history = train(x_train, y_train, model, model_path=filepath, \n",
    "                              batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, reg_param=REG_PARAM, show_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model using the test set and report performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-29 22:16:50.383448\n",
      "2018-01-29 22:17:59.473069\n",
      "Evaluation time for 68234 sequences = 69.090 secs --> 0.001013 sec/sequence\n",
      "\n",
      "Accuracy = 0.9848316088753407 \t AUC = 0.9846770382358061\n",
      "Confusion matrix:\n",
      "[[36979   516]\n",
      " [  519 30220]]\n",
      "Results saved in ./results/pred_results-sent=5-f2-now2v-strat-epoch=20-lr=0.01.txt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAligIAoERRAACUKAoAgNL/A1cz/GTy7z1AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f9efa21e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if USE_WORD2VEC:\n",
    "    ofname = './results/pred_results-sent=%d-f%d-w2v-strat-epoch=%d-lr=%.2f.txt' % (MAX_SENTS, MAX_FIELDS, NUM_EPOCHS, LEARN_RATE)\n",
    "else:\n",
    "    ofname = './results/pred_results-sent=%d-f%d-now2v-strat-epoch=%d-lr=%.2f.txt' % (MAX_SENTS, MAX_FIELDS, NUM_EPOCHS, LEARN_RATE)\n",
    "evaluate(x_test, y_test, model, save=True, outfile=ofname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report and save performance summary statistics per sequence and per disassembled executable\n",
    "**Note:** Per executable performance below takes a majority vote of all sequences in the diassembled file in order to determine the predicted label per file, i.e., executable label = class label with more sequences predicted.<br><br>\n",
    "This is a rudimentary heuristic for demonstration purposes only. Per sequence labels migt be more critical for some analysis. A runtime heuristic will be needed in order to decide when to flag a suspicious executable file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Confusion Matrix\n",
      "Predicted      0      1  __all__\n",
      "Actual                          \n",
      "0          36979    516    37495\n",
      "1            519  30220    30739\n",
      "__all__    37498  30736    68234\n",
      "Class 0: Recall = 98.62381651 Precision = 98.61592618\n",
      "Class 1: Recall = 98.31159114 Precision = 98.32118688\n",
      "Overall Accuracy = 0.9848316088753407 \t AUC = 0.9846770382358061\n",
      "\n",
      "Executable Confusion Matrix\n",
      "Predicted   0    1  __all__\n",
      "Actual                     \n",
      "0          84    0       84\n",
      "1           3  136      139\n",
      "__all__    87  136      223\n",
      "Class 0: Recall = 100.00000000 Precision = 96.55172414\n",
      "Class 1: Recall = 97.84172662 Precision = 100.00000000\n",
      "Overall Accuracy = 0.9865470852017937 \t AUC = 0.9892086330935252\n",
      "\n",
      "Per executable results and performance summary saved to ./results/pred_summary-sent=5-f2-now2v-strat-epoch=20-lr=0.01.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_confusion import ConfusionMatrix\n",
    "\n",
    "# Get performance per process\n",
    "df  = pd.read_csv(ofname, sep='\\t', header=0, encoding='utf-8')\n",
    "df1 = pd.pivot_table(df, values='proc_sid', index=['test_pid', 'y_true'], columns='y_pred', aggfunc='count', fill_value=0)\n",
    "df1['total'] = df1[0] + df1[1]\n",
    "df1['%_0'] = df1[0] * 100 / df1['total']\n",
    "df1['%_1'] = df1[1] * 100 / df1['total']\n",
    "df1['proc_label'] = df1[1] > df1[0]\n",
    "df1['proc_label'] = df1['proc_label'].astype(np.int)\n",
    "sfname = ofname.replace('pred_results', 'pred_summary')\n",
    "df1.to_csv(sfname, sep='\\t', index=True, index_label='test_pid\\ty_true', encoding='utf-8')\n",
    "\n",
    "# Get confusion matrix and overall performance metrics\n",
    "y_true = df['y_true']\n",
    "y_pred = df['y_pred']\n",
    "confusion_mtx = ConfusionMatrix(y_true, y_pred)\n",
    "print('Sequence Confusion Matrix')\n",
    "print(confusion_mtx)\n",
    "#confusion_mtx.plot()\n",
    "plt.show()\n",
    "\n",
    "ff = open(sfname, 'a')\n",
    "print('=========================================================================', file=ff)\n",
    "print('Sequence Confusion Matrix', file=ff)\n",
    "print(confusion_mtx, file=ff)\n",
    "print('=========================================================================', file=ff)\n",
    "\n",
    "cm = confusion_mtx.to_dataframe()\n",
    "correct=0\n",
    "print('Per Sequence Performance Metrics', file=ff)\n",
    "for i in range(cm.shape[0]):\n",
    "    correct += cm.iloc[i][i]\n",
    "    prec   = cm.iloc[i][i] * 100.0 / cm.sum(axis=0)[i]\n",
    "    recall = cm.iloc[i][i] * 100.0 / cm.sum(axis=1)[i]\n",
    "    print('Class %s: Recall = %.8f Precision = %.8f' % (cm.columns[i], recall, prec))\n",
    "    print('Class %s: Recall = %.8f Precision = %.8f' % (cm.columns[i], recall, prec), file=ff)\n",
    "print(\"Overall Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(y_true, y_pred), roc_auc_score(y_true, y_pred)))\n",
    "print(\"Overall Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(y_true, y_pred), roc_auc_score(y_true, y_pred)), file=ff)\n",
    "#print('=========================================================================', file=ff)\n",
    "print('')\n",
    "\n",
    "# Get process-level confusion matrix and overall performance metrics\n",
    "df2 = pd.DataFrame(columns=['y_true', 'y_pred'])\n",
    "df2['y_true'] = pd.Series(df1.index.get_level_values(1))\n",
    "df2['y_pred'] = df1['proc_label'].values\n",
    "y_true = df2['y_true']\n",
    "y_pred = df2['y_pred']\n",
    "confusion_mtx = ConfusionMatrix(y_true, y_pred)\n",
    "print('Executable Confusion Matrix')\n",
    "print(confusion_mtx)\n",
    "#confusion_mtx.plot()\n",
    "plt.show()\n",
    "\n",
    "print('=========================================================================', file=ff)\n",
    "print('Executable Confusion Matrix', file=ff)\n",
    "print(confusion_mtx, file=ff)\n",
    "print('=========================================================================', file=ff)\n",
    "\n",
    "cm = confusion_mtx.to_dataframe()\n",
    "correct=0\n",
    "print('Per Executable Performance Metrics', file=ff)\n",
    "for i in range(cm.shape[0]):\n",
    "    correct += cm.iloc[i][i]\n",
    "    prec   = cm.iloc[i][i] * 100.0 / cm.sum(axis=0)[i]\n",
    "    recall = cm.iloc[i][i] * 100.0 / cm.sum(axis=1)[i]\n",
    "    print('Class %s: Recall = %.8f Precision = %.8f' % (cm.columns[i], recall, prec))\n",
    "    print('Class %s: Recall = %.8f Precision = %.8f' % (cm.columns[i], recall, prec), file=ff)\n",
    "print(\"Overall Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(y_true, y_pred), roc_auc_score(y_true, y_pred)))\n",
    "print(\"Overall Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(y_true, y_pred), roc_auc_score(y_true, y_pred)), file=ff)\n",
    "print('=========================================================================', file=ff)\n",
    "\n",
    "ff.close()\n",
    "\n",
    "print('\\nPer executable results and performance summary saved to %s' % sfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
